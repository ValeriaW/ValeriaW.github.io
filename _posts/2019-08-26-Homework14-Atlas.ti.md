---
layout: post
title: Qualitative Data Analysis with Atlas.ti
---


My fourteenth homework post dealing with the qualitative data analysis programme Atlas.ti!
<!-- more -->

# Homework 14

***

My personal background is actually not history, but it is global studies and more specifically political psychology. Naturally, qualitative data analysis and so-called 'thick data' are a huge wealth of information that I want to compliment with big data. Why do I think the two go hand in hand?

Atlas.ti is a qualitative data analysis programme that allows for the coding of documents, interviews, audi files, videos, and images. It further allows you to code twitter data and the georeferencing of data as well. The coded data can then be used to create networks, show the relationship between the codes and combine all kinds of interconnected insights into one report. 

For historians, qualitative data analysis might not hold many uses, however for the humanities in general, qualitative data analysis is a staple and the assistance with coding, and synthesising of conclusions is invaluable. It is a also simply a great tool to create literature reviews and overviews of many docomunents on one specific topic, as is the case for a PhD or a journal article.

Facilitates the discovery of patterns and makes analysis across different formats easy in one place. Finally, it helps to generate useful data visualizations for a report, thesis or journal article.

You can collaborate with other people and work with large amounts of data.

Even though it says qualitative data analysis, the tool has evolved and you can combine qual and quant, with the main focus on assisting in the creation of a report and the export of data tables to be used in other programmes such as SPSS.

You can further import complete codebooks from previous research, to build upon deductive insights but also work from the 'bottom-up' and create codes from research in an inductive approach.

##Integration of Thick Data and Big Data

Copmlex systems data

over-dependence on quantitative data. --> not holistic

Tricia Wang

Big data is good in making predictions for contained (almost static) systems, however complex *dynamic* systems, especially systems involving human beings that are always non-linear need to be complemented by thick data. On top of that, complex systems analysis that can be achieved by programmes such as the agent-based modeling software *Netlogo*. 

Big data needs to be interpreted within the context of ethnographers, who can gather thick data

Thick data is data from humans that cannot be quantified, small sample size, but delivers depth of meaning and context to quantified static data analysis when it is applied to dynamic systems.

The dataset we worked with during the course was very big and the idea of the tools we were introduced to was to use superior scope of automated working processes to analyse data that go beyond what an individual researcher could go through efficiently.

I think it’s important to distinguish between ‘big data’ and data science more broadly. The latter refers to computationally powered quantitative analysis and modelling techniques, even when applied to ‘smaller’ data sets, while the former is over- and misused to describe exactly that. 

In that vein, analysing twitter data has become an interesting field of research in sociology, psychology and political science among other disciplines. in atlas.ti, one can simply press the button import twitter data, under the folder 'documents' and then import the set number of tweets. There is a huge drawback however, and that is the limitation that yuo can only import tweets from the past 7 days. I think this is a major flaw that severely incapacitates the utility of this tool.

![twitterimport](/img/Tweetimport.png)

The import will produce a single document with all tweets and a set of codes for the hashtags, the author, the language of the tweet and the location from where the tweet was made. The tweets themselves become quotations. So, for example, all of the tweets under the hashtag ex: ‘#DigitalHumanities’ will be quotations linked to that code. One quotation will have several codes, and each retweet is a connection. All data that is contained in one quotation can be visualized using a network of nodes, that represent different pieces of information. The relationship between each node can be set in the link manager, e.g. explains, reacts to, succeeds etc.

With the example of #ethnography, which yielded more results for the last 7 days than #digital humanities, atlas.ti created this table. All the data can be easily exported in csv format or other, to be used in gephi or further structured using python, e.g. adding coordinates to the locations of the tweets.

![Table](/img/Table_Atlas.ti.png)

This is an example from a literature review I had to write for a philosophy class about migration as a global public good.

![Kodes](/img/NetworkCodes.png)







***
